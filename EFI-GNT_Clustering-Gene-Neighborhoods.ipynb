{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Gene Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from scipy.cluster.hierarchy import linkage, fcluster, dendrogram\n",
    "from scipy.spatial.distance import pdist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "# --- Configuration for the SQLite DB ---\n",
    "# SQLITE_DB_PATH will be set in the __main__ block for convenience\n",
    "GENES_TABLE = 'attributes' # Main table for hit gene data\n",
    "NEIGHBORS_TABLE = 'neighbors' # Table for neighboring gene data\n",
    "\n",
    "COL_NEIGHBORHOOD_ID = 'organism' # Use 'organism' as the unique identifier for each neighborhood for our clustering\n",
    "COL_GENE_ID = 'id' # Unique identifier for each gene/protein in both tables\n",
    "COL_LINKING_KEY = 'id' # The linking column between 'attributes' and 'neighbors'\n",
    "COL_ACCESSION_ID = 'accession' # Column for accession (UniProt) ID\n",
    "\n",
    "COL_FUNCTION_DESC = 'desc' # Main functional description in both tables\n",
    "COL_PFAM_IDS = 'family' # Column for PFAM family IDs in both tables\n",
    "COL_INTERPRO_IDS = 'ipro_family' # Column for InterPro family IDs in both tables\n",
    "COL_REL_START = 'rel_start' # Column for relative start position\n",
    "COL_REL_STOP = 'rel_stop' # Column for relative stop position\n",
    "\n",
    "HIT_GENE_WEIGHT_FACTOR = 10 # Factor by which hit gene features are \"copied\" for emphasis\n",
    "DIRECT_NEIGHBOR_WEIGHT_FACTOR = 3 # Factor for direct neighbor domain features\n",
    "\n",
    "COL_SSN_CLUSTER_ID = 'cluster_num' # Column in 'attributes' that holds the SSN cluster ID\n",
    "# DEFAULT_SSN_CLUSTER_VALUE_TO_FILTER can be a list of values that should be ignored as valid SSN clusters\n",
    "DEFAULT_SSN_CLUSTER_VALUE_TO_FILTER = [None, 0] # Example: Filter out None or 0 as valid SSN IDs\n",
    "\n",
    "SAVE_PLOTS = True # Set to True to save plots to files\n",
    "OUTPUT_DIR = 'gnn_cluster_plots' # Directory to save plots\n",
    "REPORT_FILENAME_BASE = 'gnn_clustering_report' # Base name, will append info dynamically\n",
    "OUTPUT_FORMATS = ['svg', 'png', 'pdf'] # List of formats to save plots in\n",
    "DPI = 300 # Dots per inch for raster formats like 'png'\n",
    "HIGHLIGHT_COLOR = 'red' # Color for the original input sequence's leaf label\n",
    "\n",
    "# Dynamic plot sizing parameters\n",
    "MIN_PLOT_HEIGHT = 8 # Minimum height of the plot in inches\n",
    "HEIGHT_PER_LEAF = 0.25 # Adjust this value (e.g., 0.2 to 0.5) to compress/stretch the Y-axis\n",
    "MAX_PLOT_HEIGHT = 40 # Maximum height to prevent excessively tall plots\n",
    "\n",
    "MIN_PLOT_WIDTH = 10 # Minimum width of the plot in inches\n",
    "WIDTH_PER_LEAF = 0.3 # Adjust this value (e.g., 0.3 to 0.7) to compress/stretch the X-axis (more horizontal space for branches)\n",
    "MAX_PLOT_WIDTH = 60 # Maximum width to prevent excessively wide plots\n",
    "\n",
    "# Configuration for collapsing similar neighborhoods\n",
    "COLLAPSE_IDENTICAL_NEIGHBORHOODS = True # Set to True to enable collapsing\n",
    "COLLAPSE_CORE_SIMILARITY_THRESHOLD = 0.0 # Strict similarity for hit gene + direct neighbors. Usually 0.0 for exact matches.\n",
    "COLLAPSE_FULL_NEIGHBORHOOD_SIMILARITY_THRESHOLD = 0.3 # Similarity for the entire neighborhood. e.g., 0.3 for 70% similarity.\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def parse_annotation_string(annotation_str, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Parses a string containing annotations (e.g., function, InterPro, PFAM)\n",
    "    to extract individual features, applying a prefix.\n",
    "    Handles potential multiple IDs separated by hyphens or semicolons.\n",
    "    Does NOT split by spaces or underscores for terms like \"cysteine desulfurase\".\n",
    "    Filters out \"Uncharacterized protein\", empty strings, and 'none' values.\n",
    "    \"\"\"\n",
    "    if not isinstance(annotation_str, str) or pd.isna(annotation_str) or annotation_str.lower().strip() in ('none', '', 'null', 'uncharacterized protein'):\n",
    "        return set()\n",
    "\n",
    "    features = set()\n",
    "    # Split only by hyphens (-) and semicolons (;)\n",
    "    parts = [p.strip() for p in re.split(r'[-;]', annotation_str) if p.strip()]\n",
    "\n",
    "    for part in parts:\n",
    "        # After splitting, re-check for uninformative parts\n",
    "        if part.lower().strip() in ('none', '', 'null', 'uncharacterized protein'):\n",
    "            continue\n",
    "\n",
    "        # Prioritize InterPro and PFAM IDs if they match the patterns\n",
    "        if re.match(r'IPR\\d+', part, re.IGNORECASE):\n",
    "            features.add(f\"{prefix}{part.upper()}\")\n",
    "        elif re.match(r'PF\\d+', part, re.IGNORECASE):\n",
    "            features.add(f\"{prefix}{part.upper()}\")\n",
    "        else:\n",
    "            # General terms, clean them up slightly (collapse multiple spaces)\n",
    "            clean_part = re.sub(r'\\s+', ' ', part).lower().strip()\n",
    "\n",
    "            if clean_part: # Check if it's not empty after cleaning\n",
    "                features.add(f\"{prefix}{clean_part}\")\n",
    "    return features\n",
    "\n",
    "def extract_features_from_gene_row(gene_row, current_weight_factor=1, base_prefix=\"N_\", \n",
    "                                   include_desc=True, include_pfam=True, include_interpro=True):\n",
    "    \"\"\"\n",
    "    Extracts features (InterPro, PFAM, function terms) from a single gene row,\n",
    "    applying a base prefix and duplicating features by current_weight_factor.\n",
    "    \"\"\"\n",
    "    \n",
    "    features_set = set()\n",
    "    raw_features = set()\n",
    "\n",
    "    if include_desc:\n",
    "        function_desc = gene_row[COL_FUNCTION_DESC]\n",
    "        raw_features.update(parse_annotation_string(function_desc))\n",
    "    \n",
    "    if include_pfam:\n",
    "        pfam_ids = gene_row[COL_PFAM_IDS]\n",
    "        raw_features.update(parse_annotation_string(pfam_ids))\n",
    "    \n",
    "    if include_interpro:\n",
    "        interpro_ids = gene_row[COL_INTERPRO_IDS]\n",
    "        raw_features.update(parse_annotation_string(interpro_ids))\n",
    "\n",
    "    if current_weight_factor > 1:\n",
    "        for feature in raw_features:\n",
    "            for i in range(current_weight_factor):\n",
    "                features_set.add(f\"{base_prefix}{feature}_w{i}\") \n",
    "    else: \n",
    "        for feature in raw_features:\n",
    "            features_set.add(f\"{base_prefix}{feature}\")\n",
    "\n",
    "    return features_set\n",
    "\n",
    "\n",
    "def _plot_dendrogram(linked, neighborhood_ids_subset, labels_map, distance_threshold, \n",
    "                     plot_title_base, label_type, original_input_sequence_id,\n",
    "                     save_plots, output_dir, output_formats, dpi, \n",
    "                     min_plot_height, height_per_leaf, max_plot_height,\n",
    "                     min_plot_width, width_per_leaf, max_plot_width):\n",
    "    \"\"\"\n",
    "    Helper function to generate a single dendrogram plot.\n",
    "    \"\"\"\n",
    "    fig_title = f\"{plot_title_base} ({label_type.capitalize()} Labels)\"\n",
    "    \n",
    "    labels_to_use = []\n",
    "    # Store the hit_id for each label in the order it will be plotted, to match with xticklabels\n",
    "    accession_ids_for_labels = []\n",
    "    for nh_id in neighborhood_ids_subset:\n",
    "        organism_name, hit_id_internal, ssn_cluster_id, accession_id, _ = labels_map.get(nh_id, ('Unknown', 'Unknown', None, 'Unknown', None))\n",
    "\n",
    "        if label_type == 'organism':\n",
    "            labels_to_use.append(organism_name.rstrip('.'))\n",
    "        elif label_type == 'id': # This now means 'accession'\n",
    "            labels_to_use.append(accession_id) # Use accession_id for 'id' labels\n",
    "        else:\n",
    "            labels_to_use.append(nh_id) # Fallback, should not be hit\n",
    "        accession_ids_for_labels.append(accession_id)\n",
    "\n",
    "    # Figure size calculation\n",
    "    num_leaves = len(neighborhood_ids_subset)\n",
    "    \n",
    "    calculated_height = max(min_plot_height, num_leaves * height_per_leaf)\n",
    "    final_height = min(calculated_height, max_plot_height)\n",
    "    \n",
    "    calculated_width = max(min_plot_width, num_leaves * width_per_leaf)\n",
    "    final_width = min(calculated_width, max_plot_width)\n",
    "    \n",
    "    plt.figure(figsize=(final_width, final_height)) # Use dynamic width and height\n",
    "    \n",
    "    dendrogram(linked,\n",
    "               orientation='top',\n",
    "               labels=labels_to_use,\n",
    "               distance_sort='descending',\n",
    "               show_leaf_counts=True)\n",
    "    \n",
    "    plt.title(fig_title)\n",
    "    plt.xlabel('Gene Neighborhood (Labeled by ' + ('Accession' if label_type == 'id' else label_type.capitalize()) + ')')     # Y-axis label is now fixed to Linear Scale\n",
    "    plt.ylabel(f'Jaccard Distance (Linear Scale, Threshold: {distance_threshold})') \n",
    "    plt.axhline(y=distance_threshold, color='r', linestyle='--', label=f'Cut-off at {distance_threshold}')\n",
    "    plt.legend()\n",
    "\n",
    "    ax = plt.gca()    \n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    # Color specific leaf label\n",
    "    if original_input_sequence_id:\n",
    "        for i, tick_label in enumerate(ax.get_xticklabels()):\n",
    "            if accession_ids_for_labels[i] == original_input_sequence_id:\n",
    "                tick_label.set_color(HIGHLIGHT_COLOR)\n",
    "                tick_label.set_weight('bold') # Make it bold for more prominence\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_plots:\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        clean_plot_title_base = re.sub(r'[^\\w\\s-]', '', plot_title_base).replace(' ', '_')\n",
    "        base_filename = f\"{clean_plot_title_base}_{label_type}_labels\"\n",
    "        \n",
    "        # Save in multiple formats ---\n",
    "        for fmt in output_formats:\n",
    "            full_filename = f\"{base_filename}.{fmt}\"\n",
    "            plt.savefig(os.path.join(output_dir, full_filename), format=fmt, dpi=dpi)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def _perform_collapsing(all_neighborhood_features, full_neighborhood_labels_map, \n",
    "                        core_neighborhood_features,\n",
    "                        collapse_core_similarity_threshold, collapse_full_neighborhood_similarity_threshold,\n",
    "                        output_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Performs a two-stage collapsing of similar neighborhoods.\n",
    "    Stage 1: Group by core (hit + direct neighbors) features.\n",
    "    Stage 2: Within these groups, sub-group by full neighborhood features.\n",
    "\n",
    "    Returns: (final_neighborhood_features, final_neighborhood_labels_map, collapsed_groups_report)\n",
    "    \"\"\"\n",
    "    print(f\"{output_prefix}  Starting two-stage collapsing (Core Thr: {collapse_core_similarity_threshold}, Full Thr: {collapse_full_neighborhood_similarity_threshold}).\")\n",
    "\n",
    "    collapsed_groups_report = {}\n",
    "    \n",
    "    # --- Stage 1: Group by CORE features (hit + direct neighbors) ---\n",
    "    core_labels_ordered = sorted(list(core_neighborhood_features.keys()))\n",
    "    if len(core_labels_ordered) < 2:\n",
    "        print(f\"{output_prefix}  Only {len(core_labels_ordered)} neighborhood(s) to process. Skipping collapsing.\")\n",
    "        return all_neighborhood_features, full_neighborhood_labels_map, collapsed_groups_report\n",
    "\n",
    "    core_vocabulary = sorted(list(set.union(*core_neighborhood_features.values())))\n",
    "    if not core_vocabulary:\n",
    "        print(f\"{output_prefix}  Warning: No core features found for collapsing. Skipping collapsing step.\")\n",
    "        return all_neighborhood_features, full_neighborhood_labels_map, collapsed_groups_report\n",
    "\n",
    "    core_feature_vectors = np.array([\n",
    "        [1 if feature in core_neighborhood_features[nh_label] else 0 for feature in core_vocabulary]\n",
    "        for nh_label in core_labels_ordered\n",
    "    ])\n",
    "\n",
    "    if core_feature_vectors.shape[0] < 2: # Check again after creating vectors\n",
    "        print(f\"{output_prefix}  Only {core_feature_vectors.shape[0]} valid core feature vector(s). Skipping collapsing.\")\n",
    "        return all_neighborhood_features, full_neighborhood_labels_map, collapsed_groups_report\n",
    "\n",
    "    if all(np.array_equal(vec, core_feature_vectors[0]) for vec in core_feature_vectors):\n",
    "        core_pre_clusters = {core_labels_ordered[i]: 1 for i in range(len(core_labels_ordered))} # All to one cluster\n",
    "        print(f\"{output_prefix}  All core feature vectors are identical. Treating as one initial core group.\")\n",
    "    else:\n",
    "        core_distances = pdist(core_feature_vectors, metric='jaccard')\n",
    "        core_linked = linkage(core_distances, method='average')\n",
    "        core_pre_clusters = fcluster(core_linked, collapse_core_similarity_threshold, criterion='distance')\n",
    "    \n",
    "    # Group neighborhoods by their initial core-feature-based cluster\n",
    "    initial_core_groups = defaultdict(list)\n",
    "    for i, group_id in enumerate(core_pre_clusters):\n",
    "        initial_core_groups[group_id].append(core_labels_ordered[i])\n",
    "\n",
    "    print(f\"{output_prefix}  Stage 1: Grouped into {len(initial_core_groups)} initial core groups based on a threshold of {collapse_core_similarity_threshold}.\")\n",
    "\n",
    "    # --- Stage 2: Sub-group by FULL neighborhood features within each core group ---\n",
    "    final_neighborhood_features = {}\n",
    "    final_neighborhood_labels_map = {}\n",
    "    \n",
    "    collapsed_total_count = 0\n",
    "    unique_collapsed_group_counter = 0 # Using a single counter for all collapsed groups\n",
    "    \n",
    "    # We'll generate letter codes like A, B, ..., Z, AA, AB, ... for robustness\n",
    "    def generate_letter_code(index):\n",
    "        if index < 26:\n",
    "            return string.ascii_uppercase[index]\n",
    "        else:\n",
    "            first_char_idx = (index // 26) - 1\n",
    "            second_char_idx = index % 26\n",
    "            return f\"{string.ascii_uppercase[first_char_idx]}{string.ascii_uppercase[second_char_idx]}\"\n",
    "\n",
    "    for group_id in sorted(initial_core_groups.keys()):\n",
    "        members_in_core_group = initial_core_groups[group_id]\n",
    "        \n",
    "        if len(members_in_core_group) < 2:\n",
    "            member_label = members_in_core_group[0]\n",
    "            final_neighborhood_features[member_label] = all_neighborhood_features[member_label]\n",
    "            final_neighborhood_labels_map[member_label] = full_neighborhood_labels_map[member_label]\n",
    "            continue\n",
    "\n",
    "        sub_group_vocabulary = sorted(list(set.union(*[all_neighborhood_features[m] for m in members_in_core_group])))\n",
    "        if not sub_group_vocabulary:\n",
    "            sub_group_assignments = {m: 1 for m in members_in_core_group}\n",
    "            print(f\"{output_prefix}  Warning: No full features for core group {group_id}. Treating all {len(members_in_core_group)} as one sub-cluster.\")\n",
    "        else:\n",
    "            sub_group_feature_vectors = np.array([\n",
    "                [1 if feature in all_neighborhood_features[m] else 0 for feature in sub_group_vocabulary]\n",
    "                for m in members_in_core_group\n",
    "            ])\n",
    "            # Avoid pdist if all sub_group_feature_vectors are identical ---\n",
    "            if sub_group_feature_vectors.shape[0] > 1 and all(np.array_equal(vec, sub_group_feature_vectors[0]) for vec in sub_group_feature_vectors):\n",
    "                sub_group_assignments = {members_in_core_group[i]: 1 for i in range(len(members_in_core_group))} # All to one sub_cluster\n",
    "                print(f\"{output_prefix}  All full feature vectors in core group {group_id} are identical. Treating as one sub-cluster.\")\n",
    "            else:\n",
    "                sub_group_distances = pdist(sub_group_feature_vectors, metric='jaccard')\n",
    "                sub_group_linked = linkage(sub_group_distances, method='average')\n",
    "                sub_group_assignments = fcluster(sub_group_linked, collapse_full_neighborhood_similarity_threshold, criterion='distance')\n",
    "        \n",
    "        current_sub_groups = defaultdict(list)\n",
    "        for i, sub_cluster_id in enumerate(sub_group_assignments):\n",
    "            current_sub_groups[sub_cluster_id].append(members_in_core_group[i])\n",
    "        \n",
    "        for sub_cluster_id in sorted(current_sub_groups.keys()):\n",
    "            collapsed_members = current_sub_groups[sub_cluster_id]\n",
    "            \n",
    "            if len(collapsed_members) > 1:\n",
    "                collapsed_total_count += (len(collapsed_members) - 1)\n",
    "                \n",
    "                representative_label = collapsed_members[0]\n",
    "                \n",
    "                letter_code = generate_letter_code(unique_collapsed_group_counter)\n",
    "                unique_collapsed_group_counter += 1\n",
    "                \n",
    "                orig_organism, orig_hit_id, orig_ssn_id, orig_accession, _ = full_neighborhood_labels_map[representative_label]\n",
    "                final_neighborhood_labels_map[representative_label] = (orig_organism, orig_hit_id, orig_ssn_id, orig_accession, (len(collapsed_members), letter_code))\n",
    "                \n",
    "                collapsed_groups_report[letter_code] = {\n",
    "                    'representative': representative_label,\n",
    "                    'members': sorted(collapsed_members),\n",
    "                    'count': len(collapsed_members)\n",
    "                }\n",
    "                \n",
    "                union_features = set()\n",
    "                for member_label in collapsed_members:\n",
    "                    union_features.update(all_neighborhood_features[member_label])\n",
    "                final_neighborhood_features[representative_label] = union_features\n",
    "                \n",
    "            else:\n",
    "                member_label = collapsed_members[0]\n",
    "                final_neighborhood_features[member_label] = all_neighborhood_features[member_label]\n",
    "                final_neighborhood_labels_map[member_label] = full_neighborhood_labels_map[member_label]\n",
    "\n",
    "    if collapsed_total_count > 0:\n",
    "        print(f\"{output_prefix}  Collapsed a total of {collapsed_total_count} neighborhoods into {len(final_neighborhood_features)} unique entities after two stages.\")\n",
    "    else:\n",
    "        print(f\"{output_prefix}  No neighborhoods were collapsed after two stages (or disabled).\")\n",
    "\n",
    "    return final_neighborhood_features, final_neighborhood_labels_map, collapsed_groups_report\n",
    "\n",
    "\n",
    "def cluster_gene_neighborhoods_from_sqlite(\n",
    "    db_path,\n",
    "    genes_table=GENES_TABLE,\n",
    "    neighbors_table=NEIGHBORS_TABLE,\n",
    "    col_neighborhood_id=COL_NEIGHBORHOOD_ID,\n",
    "    col_gene_id=COL_GENE_ID,\n",
    "    col_linking_key=COL_LINKING_KEY,\n",
    "    col_accession_id=COL_ACCESSION_ID,\n",
    "    col_function_desc=COL_FUNCTION_DESC,\n",
    "    col_pfam_ids=COL_PFAM_IDS,\n",
    "    col_interpro_ids=COL_INTERPRO_IDS,\n",
    "    col_rel_start=COL_REL_START, \n",
    "    col_rel_stop=COL_REL_STOP,   \n",
    "    col_ssn_cluster_id=COL_SSN_CLUSTER_ID,\n",
    "    hit_gene_weight_factor=HIT_GENE_WEIGHT_FACTOR,\n",
    "    direct_neighbor_weight_factor=DIRECT_NEIGHBOR_WEIGHT_FACTOR, \n",
    "    differentiate_by_ssn_cluster=False,\n",
    "    ssn_cluster_value_to_filter=DEFAULT_SSN_CLUSTER_VALUE_TO_FILTER,\n",
    "    collapse_identical_neighborhoods=COLLAPSE_IDENTICAL_NEIGHBORHOODS,\n",
    "    collapse_core_similarity_threshold=COLLAPSE_CORE_SIMILARITY_THRESHOLD,\n",
    "    collapse_full_neighborhood_similarity_threshold=COLLAPSE_FULL_NEIGHBORHOOD_SIMILARITY_THRESHOLD,\n",
    "    original_input_sequence_id=None,\n",
    "    distance_threshold=0.8,\n",
    "    plot_dendrogram=True,\n",
    "    save_plots=SAVE_PLOTS,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    output_formats=OUTPUT_FORMATS, \n",
    "    dpi=DPI,\n",
    "    min_plot_height=MIN_PLOT_HEIGHT, \n",
    "    height_per_leaf=HEIGHT_PER_LEAF, \n",
    "    max_plot_height=MAX_PLOT_HEIGHT,\n",
    "    min_plot_width=MIN_PLOT_WIDTH,\n",
    "    width_per_leaf=WIDTH_PER_LEAF,\n",
    "    max_plot_width=MAX_PLOT_WIDTH\n",
    "):\n",
    "    \"\"\"\n",
    "    Clusters gene neighborhoods from an SQLite database based on detailed functional annotations,\n",
    "    considering every row in 'attributes' as a hit gene and including its neighbors.\n",
    "    Applies extra weight to the hit gene and direct neighbors.\n",
    "    Optionally differentiates by SSN cluster.\n",
    "    Can collapse highly similar neighborhoods (hit + direct neighbors + entire neighborhood) for plotting.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing (clusters_dict, full_neighborhood_labels_map, collapsed_groups_report).\n",
    "               clusters_dict is a dict where keys are SSN cluster IDs (or 'All' if no differentiation)\n",
    "               and values are dicts of cluster_id -> list of unique_neighborhood_labels (which might be representatives).\n",
    "               final_labels_map is a dict mapping unique_neighborhood_label to (organism, hit_id, ssn_cluster_id, accession_id, collapsed_members_info).\n",
    "               collapsed_groups_report is a dict detailing the collapsed groups.\n",
    "    \"\"\"\n",
    "\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    conn.row_factory = sqlite3.Row # Allows accessing columns by name\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    all_neighborhood_features = defaultdict(set) # Full features for main clustering and full-neighborhood-similarity check\n",
    "    core_neighborhood_features = defaultdict(set) # Subset features for strict core comparison for collapsing\n",
    "\n",
    "    full_neighborhood_labels_map = {} # Stores (organism, hit_id, ssn_id, accession, collapsed_info)\n",
    "\n",
    "\n",
    "    # 1. Fetch all 'hit genes' from the 'attributes' table\n",
    "    hit_gene_select_columns = [\n",
    "        col_gene_id,\n",
    "        col_neighborhood_id,\n",
    "        col_function_desc,\n",
    "        col_pfam_ids,\n",
    "        col_interpro_ids,\n",
    "        col_ssn_cluster_id,\n",
    "        col_accession_id,\n",
    "    ]\n",
    "    query_hit_genes = f\"SELECT {', '.join(hit_gene_select_columns)} FROM {genes_table}\"\n",
    "    cursor.execute(query_hit_genes)\n",
    "    hit_genes_data = cursor.fetchall()\n",
    "\n",
    "    if not hit_genes_data:\n",
    "        print(\"No hit genes found in the 'attributes' table. Please check your database and configuration.\")\n",
    "        conn.close()\n",
    "        return {}, {}\n",
    "\n",
    "    raw_ssn_ids_counts = defaultdict(int)\n",
    "    \n",
    "    for hit_row in hit_genes_data:\n",
    "        hit_id = hit_row[col_gene_id]\n",
    "        organism_name = hit_row[col_neighborhood_id]\n",
    "        ssn_cluster_id = hit_row[col_ssn_cluster_id]\n",
    "        accession_id = hit_row[col_accession_id]\n",
    "        \n",
    "        raw_ssn_ids_counts[ssn_cluster_id] += 1\n",
    "\n",
    "        unique_neighborhood_label = f\"{organism_name}_{hit_id}\"\n",
    "        \n",
    "        current_full_features = set() # Accumulates features for the entire neighborhood\n",
    "        current_core_features = set() # Accumulates features for hit + direct neighbors for collapsing\n",
    "\n",
    "        # Add features of the HIT gene itself\n",
    "        # For FULL features, use HIT_ prefix and full weight factor\n",
    "        hit_full_features = extract_features_from_gene_row(\n",
    "            gene_row=hit_row, \n",
    "            current_weight_factor=hit_gene_weight_factor,\n",
    "            base_prefix=\"HIT_\",\n",
    "            include_desc=True, include_pfam=True, include_interpro=True\n",
    "        )\n",
    "        current_full_features.update(hit_full_features)\n",
    "        \n",
    "        # For CORE features (used for collapsing), use COLLAPSE_ prefix, no extra weighting, maybe simplified annotations\n",
    "        hit_core_features = extract_features_from_gene_row(\n",
    "            gene_row=hit_row, \n",
    "            current_weight_factor=1, # No extra weight for collapsing criteria\n",
    "            base_prefix=\"HIT_CORE_\", # Unique prefix for core features\n",
    "            include_desc=False, include_pfam=True, include_interpro=True # Only PFAM/InterPro for core\n",
    "        )\n",
    "        current_core_features.update(hit_core_features)\n",
    "\n",
    "        full_neighborhood_labels_map[unique_neighborhood_label] = (organism_name, hit_id, ssn_cluster_id, accession_id, None)\n",
    "\n",
    "        # 2. Fetch NEIGHBOR genes for this specific hit gene's neighborhood\n",
    "        # Include rel_start and rel_stop to identify direct neighbors\n",
    "        neighbor_select_columns = [\n",
    "            col_gene_id,\n",
    "            col_function_desc,\n",
    "            col_pfam_ids,\n",
    "            col_interpro_ids,\n",
    "            col_rel_start, \n",
    "            col_rel_stop,  \n",
    "        ]\n",
    "        query_neighbors = f\"\"\"\n",
    "            SELECT {', '.join(neighbor_select_columns)}\n",
    "            FROM {neighbors_table}\n",
    "            WHERE {col_linking_key} = ?\n",
    "        \"\"\"\n",
    "        cursor.execute(query_neighbors, (hit_id,))\n",
    "        raw_neighbor_genes_data = cursor.fetchall() # Store raw data to find direct neighbors\n",
    "\n",
    "        # Identify direct neighbors based on closest rel_start/stop to 0\n",
    "        closest_left_neighbor_gene_id = None\n",
    "        closest_right_neighbor_gene_id = None\n",
    "        max_neg_rel_stop = -np.inf # Largest negative value, closest to 0 from left\n",
    "        min_pos_rel_start = np.inf  # Smallest positive value, closest to 0 from right\n",
    "\n",
    "        for neighbor_row in raw_neighbor_genes_data:\n",
    "            rel_start = neighbor_row[col_rel_start]\n",
    "            rel_stop = neighbor_row[col_rel_stop]\n",
    "            neighbor_gene_id = neighbor_row[col_gene_id]\n",
    "\n",
    "            if rel_stop is not None and rel_stop < 0 and rel_stop > max_neg_rel_stop:\n",
    "                max_neg_rel_stop = rel_stop\n",
    "                closest_left_neighbor_gene_id = neighbor_gene_id\n",
    "\n",
    "            if rel_start is not None and rel_start > 0 and rel_start < min_pos_rel_start:\n",
    "                min_pos_rel_start = rel_start\n",
    "                closest_right_neighbor_gene_id = neighbor_gene_id\n",
    "            \n",
    "        for neighbor_row in raw_neighbor_genes_data:\n",
    "            neighbor_gene_id = neighbor_row[col_gene_id]\n",
    "            \n",
    "            current_neighbor_weight_factor = 1 # Default for other neighbors (for full features)\n",
    "            is_direct_neighbor = False\n",
    "\n",
    "            if (closest_left_neighbor_gene_id is not None and neighbor_gene_id == closest_left_neighbor_gene_id) or \\\n",
    "               (closest_right_neighbor_gene_id is not None and neighbor_gene_id == closest_right_neighbor_gene_id):\n",
    "                current_neighbor_weight_factor = direct_neighbor_weight_factor\n",
    "                is_direct_neighbor = True\n",
    "            \n",
    "            # For FULL features, apply N_ prefix and appropriate weight factor\n",
    "            neighbor_full_features = extract_features_from_gene_row(\n",
    "                gene_row=neighbor_row, \n",
    "                current_weight_factor=current_neighbor_weight_factor,\n",
    "                base_prefix=\"N_\",\n",
    "                include_desc=True, include_pfam=True, include_interpro=True\n",
    "            ) \n",
    "            current_full_features.update(neighbor_full_features)\n",
    "\n",
    "            if is_direct_neighbor: # For CORE features, only direct neighbors get special prefix\n",
    "                 neighbor_core_features = extract_features_from_gene_row(\n",
    "                    gene_row=neighbor_row, \n",
    "                    current_weight_factor=1, # No extra weight for collapsing criteria\n",
    "                    base_prefix=\"N_CORE_\", # Unique prefix for core features\n",
    "                    include_desc=False, include_pfam=True, include_interpro=True # Only PFAM/InterPro for core\n",
    "                )\n",
    "                 current_core_features.update(neighbor_core_features)\n",
    "            # Other neighbors (not direct) do NOT contribute to core_features for collapsing\n",
    "\n",
    "        all_neighborhood_features[unique_neighborhood_label].update(current_full_features)\n",
    "        core_neighborhood_features[unique_neighborhood_label].update(current_core_features) # Store core features\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "    print(\"\\n--- Diagnostic: Raw SSN Cluster ID Distribution in 'attributes' table ---\")\n",
    "    for ssn_id, count in sorted(raw_ssn_ids_counts.items(), key=lambda item: str(item[0])):\n",
    "        print(f\"  SSN ID '{ssn_id}': {count} neighborhoods\")\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "\n",
    "    if not all_neighborhood_features:\n",
    "        print(\"No gene neighborhoods found or parsed. Exiting.\")\n",
    "        return {}, {}, {}\n",
    "\n",
    "    all_unique_features_vocabulary_initial = sorted(list(set.union(*all_neighborhood_features.values())))\n",
    "    \n",
    "    if not all_unique_features_vocabulary_initial:\n",
    "        print(\"No significant features extracted for clustering from any neighborhood. Check parsing logic and data. Exiting.\")\n",
    "        return {1: list(all_neighborhood_features.keys())}, full_neighborhood_labels_map, {} \n",
    "\n",
    "    # Pre-clustering (collapsing) similar neighborhoods \n",
    "    if collapse_identical_neighborhoods:\n",
    "        final_neighborhood_features, final_neighborhood_labels_map, collapsed_groups_report = \\\n",
    "            _perform_collapsing(all_neighborhood_features, full_neighborhood_labels_map, \n",
    "                                core_neighborhood_features,\n",
    "                                collapse_core_similarity_threshold, collapse_full_neighborhood_similarity_threshold)\n",
    "    else:\n",
    "        print(\"\\nCollapsing identical/similar neighborhoods is disabled. Proceeding with all original neighborhoods.\")\n",
    "        final_neighborhood_features = all_neighborhood_features\n",
    "        final_neighborhood_labels_map = full_neighborhood_labels_map\n",
    "        collapsed_groups_report = {}\n",
    "\n",
    "\n",
    "    # Continue with main clustering using final_neighborhood_features and final_neighborhood_labels_map\n",
    "    all_unique_features_vocabulary = sorted(list(set.union(*final_neighborhood_features.values()))) # Use final features\n",
    "    \n",
    "    if not all_unique_features_vocabulary:\n",
    "        print(\"No significant features extracted from final neighborhoods for clustering. Check parsing logic and data. Exiting.\")\n",
    "        return {1: list(final_neighborhood_features.keys())}, final_neighborhood_labels_map, collapsed_groups_report\n",
    "\n",
    "    ssn_clusters_to_process = defaultdict(list)\n",
    "    if differentiate_by_ssn_cluster:\n",
    "        for nh_label, (_, _, ssn_id, _, _) in full_neighborhood_labels_map.items(): # <<< This is the problematic line\n",
    "            if ssn_id not in ssn_cluster_value_to_filter:\n",
    "                ssn_clusters_to_process[ssn_id].append(nh_label)\n",
    "            else:\n",
    "                print(f\"  Diagnostic: Skipping neighborhood {nh_label} (SSN ID '{ssn_id}') due to filtering by '{ssn_cluster_value_to_filter}'.\")\n",
    "                \n",
    "        print(f\"\\nFound {len(ssn_clusters_to_process)} distinct SSN clusters to process (after filtering invalid IDs).\")\n",
    "        if ssn_clusters_to_process:\n",
    "            print(f\"  SSN Clusters to be processed: {sorted(list(ssn_clusters_to_process.keys()), key=str)}\")\n",
    "    else:\n",
    "        ssn_clusters_to_process['All_Neighborhoods'] = sorted(list(final_neighborhood_features.keys())) # Use final features\n",
    "        print(\"Processing all neighborhoods together (no SSN cluster differentiation).\")\n",
    "\n",
    "    clusters_output_dict = defaultdict(dict) \n",
    "    \n",
    "    if differentiate_by_ssn_cluster and not ssn_clusters_to_process:\n",
    "        print(\"\\nNo valid SSN clusters with any neighborhoods found after filtering for differentiation. No plots/reports generated for individual SSN clusters.\")\n",
    "        return {}, final_neighborhood_labels_map, collapsed_groups_report\n",
    "\n",
    "\n",
    "    for ssn_id, neighborhood_labels_in_ssn_cluster in ssn_clusters_to_process.items():\n",
    "        if differentiate_by_ssn_cluster:\n",
    "            print(f\"\\n--- Processing SSN Cluster: {ssn_id} (contains {len(neighborhood_labels_in_ssn_cluster)} neighborhoods) ---\")\n",
    "            plot_title_prefix = f\"SSN Cluster {ssn_id}\"\n",
    "        else:\n",
    "            plot_title_prefix = \"All Gene Neighborhoods\"\n",
    "\n",
    "        current_ssn_neighborhood_features = {\n",
    "            label: final_neighborhood_features[label] for label in neighborhood_labels_in_ssn_cluster # Use final features\n",
    "        }\n",
    "        current_ssn_neighborhood_labels_map = {\n",
    "            label: final_neighborhood_labels_map[label] for label in neighborhood_labels_in_ssn_cluster # Use final map\n",
    "        }\n",
    "\n",
    "        num_neighborhoods_in_group = len(current_ssn_neighborhood_features)\n",
    "        if num_neighborhoods_in_group < 2:\n",
    "            print(f\"  Skipping SSN Cluster {ssn_id}: Not enough distinct neighborhoods ({num_neighborhoods_in_group}) for clustering. Requires at least 2.\")\n",
    "            clusters_output_dict[ssn_id] = {1: neighborhood_labels_in_ssn_cluster}\n",
    "            continue\n",
    "\n",
    "        neighborhood_ids_sorted = sorted(list(current_ssn_neighborhood_features.keys()))\n",
    "        feature_vectors = []\n",
    "        for nh_id in neighborhood_ids_sorted:\n",
    "            vector = [1 if feature in current_ssn_neighborhood_features[nh_id] else 0 for feature in all_unique_features_vocabulary]\n",
    "            feature_vectors.append(vector)\n",
    "        \n",
    "        if all(np.array_equal(vec, feature_vectors[0]) for vec in feature_vectors):\n",
    "            print(f\"  All neighborhoods in {plot_title_prefix} have identical features. No meaningful distance calculated. Skipping plotting.\")\n",
    "            clusters_output_dict[ssn_id] = {1: neighborhood_labels_in_ssn_cluster}\n",
    "            if plot_dendrogram:\n",
    "                 print(f\"  (No plots generated for {plot_title_prefix} due to identical features)\")\n",
    "            continue\n",
    "            \n",
    "        distances = pdist(np.array(feature_vectors), metric='jaccard')\n",
    "        linked = linkage(distances, method='average')\n",
    "\n",
    "        if plot_dendrogram:\n",
    "            # Organism Labels\n",
    "            _plot_dendrogram(linked, neighborhood_ids_sorted, current_ssn_neighborhood_labels_map, distance_threshold, \n",
    "                            f\"{plot_title_prefix} GNN\", 'organism', \n",
    "                            original_input_sequence_id, \n",
    "                            save_plots, output_dir, output_formats, dpi, \n",
    "                            min_plot_height, height_per_leaf, max_plot_height,\n",
    "                            min_plot_width, width_per_leaf, max_plot_width)\n",
    "            # ID Labels\n",
    "            _plot_dendrogram(linked, neighborhood_ids_sorted, current_ssn_neighborhood_labels_map, distance_threshold, \n",
    "                            f\"{plot_title_prefix} GNN\", 'id', \n",
    "                            original_input_sequence_id, \n",
    "                            save_plots, output_dir, output_formats, dpi, \n",
    "                            min_plot_height, height_per_leaf, max_plot_height,\n",
    "                            min_plot_width, width_per_leaf, max_plot_width) \n",
    "            \n",
    "        cluster_assignments = fcluster(linked, distance_threshold, criterion='distance')\n",
    "        current_ssn_clusters = defaultdict(list)\n",
    "        for i, cluster_id in enumerate(cluster_assignments):\n",
    "            current_ssn_clusters[cluster_id].append(neighborhood_ids_sorted[i])\n",
    "        \n",
    "        clusters_output_dict[ssn_id] = current_ssn_clusters\n",
    "\n",
    "    return clusters_output_dict, full_neighborhood_labels_map, collapsed_groups_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GNN Clustering Report (2025-08-29 21:19:18) ---\n",
      "Database: 39094_CaMES_10k-Blast_noFilter_40ID-60AST_min950AA_10N.sqlite\n",
      "Jaccard Distance Threshold: 0.5\n",
      "Hit Gene Weight Factor: 10\n",
      "Direct Neighbor Weight Factor: 3\n",
      "Clustering differentiated by SSN Cluster ID (column: 'cluster_num').\n",
      "Collapsing identical/similar neighborhoods enabled:\n",
      "  Stage 1 (Hit+Direct Neighbor Core): Threshold 0.0\n",
      "  Stage 2 (Full Neighborhood): Threshold 0.3\n",
      "Original Input Sequence Accession ID for highlighting: 'A0A7V4WV16' (colored 'red')\n",
      "Plots saved to: gnn_cluster_plots in ['svg', 'png', 'pdf'] formats at 300 DPI.\n",
      "Report also saved to: gnn_cluster_plots\\gnn_clustering_report_ssn_differentiated.txt\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Diagnostic: Raw SSN Cluster ID Distribution in 'attributes' table ---\n",
      "  SSN ID '1': 102 neighborhoods\n",
      "-------------------------------------------------------------------\n",
      "  Starting two-stage collapsing (Core Thr: 0.0, Full Thr: 0.3).\n",
      "  Stage 1: Grouped into 102 initial core groups based on a threshold of 0.0.\n",
      "  No neighborhoods were collapsed after two stages (or disabled).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 59\u001b[0m\n\u001b[0;32m     55\u001b[0m write_and_print(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReport also saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreport_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m write_and_print(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m clusters_by_ssn, final_labels_map, collapsed_groups_report \u001b[38;5;241m=\u001b[39m \u001b[43mcluster_gene_neighborhoods_from_sqlite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdb_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSQLITE_DB_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcol_accession_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCOL_ACCESSION_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcol_rel_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCOL_REL_START\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcol_rel_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCOL_REL_STOP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mhit_gene_weight_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHIT_GENE_WEIGHT_FACTOR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdirect_neighbor_weight_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDIRECT_NEIGHBOR_WEIGHT_FACTOR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdifferentiate_by_ssn_cluster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDIFFERENTIATE_BY_SSN_CLUSTER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mssn_cluster_value_to_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEFAULT_SSN_CLUSTER_VALUE_TO_FILTER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcollapse_identical_neighborhoods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCOLLAPSE_IDENTICAL_NEIGHBORHOODS_ACTIVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcollapse_core_similarity_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCOLLAPSE_CORE_SIMILARITY_THRESHOLD_ACTIVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcollapse_full_neighborhood_similarity_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCOLLAPSE_FULL_NEIGHBORHOOD_SIMILARITY_THRESHOLD_ACTIVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43moriginal_input_sequence_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mORIGINAL_INPUT_SEQUENCE_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdistance_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchosen_distance_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mplot_dendrogram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43msave_plots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAVE_PLOTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43moutput_formats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUTPUT_FORMATS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDPI\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmin_plot_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMIN_PLOT_HEIGHT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mheight_per_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHEIGHT_PER_LEAF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmax_plot_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_PLOT_HEIGHT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmin_plot_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMIN_PLOT_WIDTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mwidth_per_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWIDTH_PER_LEAF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmax_plot_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_PLOT_WIDTH\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clusters_by_ssn:\n\u001b[0;32m     87\u001b[0m     write_and_print(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Final Clustering Results ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 558\u001b[0m, in \u001b[0;36mcluster_gene_neighborhoods_from_sqlite\u001b[1;34m(db_path, genes_table, neighbors_table, col_neighborhood_id, col_gene_id, col_linking_key, col_accession_id, col_function_desc, col_pfam_ids, col_interpro_ids, col_rel_start, col_rel_stop, col_ssn_cluster_id, hit_gene_weight_factor, direct_neighbor_weight_factor, differentiate_by_ssn_cluster, ssn_cluster_value_to_filter, collapse_identical_neighborhoods, collapse_core_similarity_threshold, collapse_full_neighborhood_similarity_threshold, original_input_sequence_id, distance_threshold, plot_dendrogram, save_plots, output_dir, output_formats, dpi, min_plot_height, height_per_leaf, max_plot_height, min_plot_width, width_per_leaf, max_plot_width)\u001b[0m\n\u001b[0;32m    556\u001b[0m ssn_clusters_to_process \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m differentiate_by_ssn_cluster:\n\u001b[1;32m--> 558\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m nh_label, (_, _, ssn_id) \u001b[38;5;129;01min\u001b[39;00m full_neighborhood_labels_map\u001b[38;5;241m.\u001b[39mitems(): \u001b[38;5;66;03m# <<< This is the problematic line\u001b[39;00m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m ssn_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ssn_cluster_value_to_filter:\n\u001b[0;32m    560\u001b[0m             ssn_clusters_to_process[ssn_id]\u001b[38;5;241m.\u001b[39mappend(nh_label)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# SQLITE_DB_PATH = '39061_CaMES_10kBlast_10e_50eEdge_noFilter_300AST_min900AA_withoutEgtD_withoutMethyltrans.sqlite' \n",
    "# SQLITE_DB_PATH = '39063_CaMES_10kBlast_10e_50eEdge_noFilter_300AST_min900AA-clusterseperated_10N.sqlite' \n",
    "SQLITE_DB_PATH = '39094_CaMES_10k-Blast_noFilter_40ID-60AST_min950AA_10N.sqlite' \n",
    "# SQLITE_DB_PATH = '39151_EanB_10k_Blast_noFilter_50ASTcolorized_onlybigCluster-renamed_10N.sqlite'\n",
    "# SQLITE_DB_PATH = '39150_OvoA_10k_Blast_search_noFilter_80ASTcolorized_onlyBigCluster-separated_10N.sqlite'\n",
    "\n",
    "# Set this to the UniProt ID of your original query protein if you want to highlight it.\n",
    "# Set to None or an empty string if you don't want to highlight any specific protein.\n",
    "ORIGINAL_INPUT_SEQUENCE_ID = 'A0A7V4WV16' # e.g., 'A0A0B0EG43' or None or ''\n",
    "\n",
    "# You can change this setting here or keep the global config\n",
    "DIFFERENTIATE_BY_SSN_CLUSTER = True     # Set to True or False as needed\n",
    "chosen_distance_threshold = 0.5         # Change as needed\n",
    "\n",
    "# Configuration for collapsing similar neighborhoods (Local Override)\n",
    "COLLAPSE_IDENTICAL_NEIGHBORHOODS_ACTIVE = True \n",
    "COLLAPSE_CORE_SIMILARITY_THRESHOLD_ACTIVE = 0.0 # Use 0.0 for exact match of hit+direct neighbors\n",
    "COLLAPSE_FULL_NEIGHBORHOOD_SIMILARITY_THRESHOLD_ACTIVE = 0.3 # e.g., 0.3 for 70% similarity of full neighborhood\n",
    "\n",
    "# Prepare report file\n",
    "report_suffix = \"_ssn_differentiated\" if DIFFERENTIATE_BY_SSN_CLUSTER else \"_all_neighborhoods\"\n",
    "report_filename = f\"{REPORT_FILENAME_BASE}{report_suffix}.txt\"\n",
    "report_path = os.path.join(OUTPUT_DIR, report_filename)\n",
    "    \n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR) # Ensure output directory exists for report and plots\n",
    "\n",
    "with open(report_path, 'w') as report_file:\n",
    "    def write_and_print(text):\n",
    "        print(text)\n",
    "        report_file.write(text + '\\n')\n",
    "\n",
    "    write_and_print(f\"\\n--- GNN Clustering Report ({datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}) ---\") \n",
    "    write_and_print(f\"Database: {SQLITE_DB_PATH}\")\n",
    "    write_and_print(f\"Jaccard Distance Threshold: {chosen_distance_threshold}\")\n",
    "    write_and_print(f\"Hit Gene Weight Factor: {HIT_GENE_WEIGHT_FACTOR}\")\n",
    "    write_and_print(f\"Direct Neighbor Weight Factor: {DIRECT_NEIGHBOR_WEIGHT_FACTOR}\")\n",
    "    if DIFFERENTIATE_BY_SSN_CLUSTER:\n",
    "        write_and_print(f\"Clustering differentiated by SSN Cluster ID (column: '{COL_SSN_CLUSTER_ID}').\")\n",
    "    else:\n",
    "        write_and_print(\"Clustering all neighborhoods together (no SSN cluster differentiation).\")\n",
    "    \n",
    "    if COLLAPSE_IDENTICAL_NEIGHBORHOODS_ACTIVE:\n",
    "        write_and_print(f\"Collapsing identical/similar neighborhoods enabled:\")\n",
    "        write_and_print(f\"  Stage 1 (Hit+Direct Neighbor Core): Threshold {COLLAPSE_CORE_SIMILARITY_THRESHOLD_ACTIVE}\")\n",
    "        write_and_print(f\"  Stage 2 (Full Neighborhood): Threshold {COLLAPSE_FULL_NEIGHBORHOOD_SIMILARITY_THRESHOLD_ACTIVE}\")\n",
    "    else:\n",
    "        write_and_print(\"Collapsing identical/similar neighborhoods disabled.\")\n",
    "\n",
    "    if ORIGINAL_INPUT_SEQUENCE_ID:\n",
    "        write_and_print(f\"Original Input Sequence Accession ID for highlighting: '{ORIGINAL_INPUT_SEQUENCE_ID}' (colored '{HIGHLIGHT_COLOR}')\")\n",
    "    else:\n",
    "        write_and_print(\"No specific original input sequence ID provided for highlighting.\")\n",
    "    write_and_print(f\"Plots saved to: {OUTPUT_DIR} in {OUTPUT_FORMATS} formats at {DPI} DPI.\")\n",
    "    write_and_print(f\"Report also saved to: {report_path}\")\n",
    "    write_and_print(\"-\" * 70)\n",
    "\n",
    "\n",
    "    clusters_by_ssn, final_labels_map, collapsed_groups_report = cluster_gene_neighborhoods_from_sqlite(\n",
    "                                            db_path=SQLITE_DB_PATH,\n",
    "                                            col_accession_id=COL_ACCESSION_ID,\n",
    "                                            col_rel_start=COL_REL_START,\n",
    "                                            col_rel_stop=COL_REL_STOP,\n",
    "                                            hit_gene_weight_factor=HIT_GENE_WEIGHT_FACTOR,\n",
    "                                            direct_neighbor_weight_factor=DIRECT_NEIGHBOR_WEIGHT_FACTOR,\n",
    "                                            differentiate_by_ssn_cluster=DIFFERENTIATE_BY_SSN_CLUSTER,\n",
    "                                            ssn_cluster_value_to_filter=DEFAULT_SSN_CLUSTER_VALUE_TO_FILTER,\n",
    "                                            collapse_identical_neighborhoods=COLLAPSE_IDENTICAL_NEIGHBORHOODS_ACTIVE,\n",
    "                                            collapse_core_similarity_threshold=COLLAPSE_CORE_SIMILARITY_THRESHOLD_ACTIVE,\n",
    "                                            collapse_full_neighborhood_similarity_threshold=COLLAPSE_FULL_NEIGHBORHOOD_SIMILARITY_THRESHOLD_ACTIVE,\n",
    "                                            original_input_sequence_id=ORIGINAL_INPUT_SEQUENCE_ID,\n",
    "                                            distance_threshold=chosen_distance_threshold,\n",
    "                                            plot_dendrogram=True,\n",
    "                                            save_plots=SAVE_PLOTS,\n",
    "                                            output_dir=OUTPUT_DIR,\n",
    "                                            output_formats=OUTPUT_FORMATS, \n",
    "                                            dpi=DPI,\n",
    "                                            min_plot_height=MIN_PLOT_HEIGHT,\n",
    "                                            height_per_leaf=HEIGHT_PER_LEAF, \n",
    "                                            max_plot_height=MAX_PLOT_HEIGHT,\n",
    "                                            min_plot_width=MIN_PLOT_WIDTH, \n",
    "                                            width_per_leaf=WIDTH_PER_LEAF, \n",
    "                                            max_plot_width=MAX_PLOT_WIDTH  \n",
    "                                        )\n",
    "\n",
    "    if clusters_by_ssn:\n",
    "        write_and_print(\"\\n--- Final Clustering Results ---\")\n",
    "        for ssn_id, clusters_in_ssn in sorted(clusters_by_ssn.items(), key=lambda item: str(item[0])):\n",
    "            write_and_print(f\"\\n### Results for SSN Cluster: {ssn_id} ###\")\n",
    "            if not clusters_in_ssn:\n",
    "                write_and_print(\"  No clusters formed for this SSN group, or insufficient data.\")\n",
    "                continue\n",
    "\n",
    "            for cluster_id, neighborhoods_in_cluster in sorted(clusters_in_ssn.items()):\n",
    "                write_and_print(f\"  Cluster {cluster_id}: {len(neighborhoods_in_cluster)} neighborhoods\")\n",
    "                for nh_id in neighborhoods_in_cluster:\n",
    "                    organism_name, hit_id_internal, _, accession_id, collapsed_info = final_labels_map.get(nh_id, ('UNKNOWN', 'UNKNOWN', None, 'UNKNOWN', None))\n",
    "                    \n",
    "                    highlight_indicator = \" (ORIGINAL INPUT)\" if accession_id == ORIGINAL_INPUT_SEQUENCE_ID else \"\"\n",
    "                    collapsed_suffix = \"\"\n",
    "                    if collapsed_info:\n",
    "                        count, letter_code = collapsed_info\n",
    "                        collapsed_suffix = f\" (Collapsed: {count} neighborhoods, Ref: {letter_code})\"\n",
    "                    \n",
    "                    write_and_print(f\"    - Organism: {organism_name}, Hit Accession: {accession_id}{highlight_indicator}{collapsed_suffix} (Internal ID: {hit_id_internal}) (Neighborhood ID: {nh_id})\")\n",
    "            write_and_print(\"  \" + \"-\" * 30)\n",
    "        \n",
    "        # --- NEW: Report on Collapsed Groups ---\n",
    "        if collapsed_groups_report:\n",
    "            write_and_print(\"\\n--- Detailed Report on Collapsed Neighborhood Groups ---\")\n",
    "            for code, group_data in sorted(collapsed_groups_report.items()):\n",
    "                write_and_print(f\"  Group ({code}): Representative: {group_data['representative']} (Total: {group_data['count']} members)\")\n",
    "                for member_nh_id in group_data['members']:\n",
    "                    member_organism, member_hit_id, _, member_accession, _ = final_labels_map.get(member_nh_id, ('UNKNOWN', 'UNKNOWN', None, 'UNKNOWN', None)) # <<< IMPORTANT: Use final_labels_map here\n",
    "                    write_and_print(f\"    - {member_organism} (Accession: {member_accession}) (Internal ID: {member_hit_id}) (NH ID: {member_nh_id})\")\n",
    "            write_and_print(\"-------------------------------------------------------\")\n",
    "    else:\n",
    "        write_and_print(\"\\nNo clusters formed at all. This could mean your database is empty, or no features were extracted after filtering, or no valid SSN clusters with multiple neighborhoods were found.\")\n",
    "\n",
    "    write_and_print(\"\\n--- Report End ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
